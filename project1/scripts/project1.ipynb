{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_helper import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process\n",
    "# Maybe subtract min? how do we treat values like -999?\n",
    "std = np.std(tX, axis=0)\n",
    "tX = tX / std\n",
    "std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required implementations\n",
    "\n",
    "max_iters = 50\n",
    "# least square\n",
    "# gamma = 0.0000001\n",
    "# logistic\n",
    "gamma = 0.01 \n",
    "batch_size = 32\n",
    "lambda_ = 0.1\n",
    "# initial_w = np.random.rand(tX.shape[1]) * 2 - 1\n",
    "# weights, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "# weights, loss = least_squares_SGD(y, tX, initial_w, batch_size, max_iters, gamma)\n",
    "# weights, loss = least_squares(y, tX)\n",
    "# weights, loss = ridge_regression(y, tX, lambda_)\n",
    "# weights, loss = logistic_regression_GD(y, tX, initial_w, max_iters, gamma)\n",
    "# weights, loss = reg_logistic_regression_SGD(y, tX, lambda_, initial_w, batch_size, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: loss=0.2985015609808699\n",
      "Lambda 1e-05, Train accuracy 0.7921377777777778, Validation Accuracy 0.79316\n",
      "Ridge Regression: loss=0.29893844163494243\n",
      "Lambda 1.4873521072935119e-05, Train accuracy 0.7916355555555555, Validation Accuracy 0.79312\n",
      "Ridge Regression: loss=0.299500537553365\n",
      "Lambda 2.21221629107045e-05, Train accuracy 0.7912, Validation Accuracy 0.79204\n",
      "Ridge Regression: loss=0.3001631836394837\n",
      "Lambda 3.290344562312671e-05, Train accuracy 0.7906622222222223, Validation Accuracy 0.79104\n",
      "Ridge Regression: loss=0.3008782202251289\n",
      "Lambda 4.893900918477499e-05, Train accuracy 0.7899955555555556, Validation Accuracy 0.7904\n",
      "Ridge Regression: loss=0.30159740112681827\n",
      "Lambda 7.278953843983146e-05, Train accuracy 0.7890933333333333, Validation Accuracy 0.78908\n",
      "Ridge Regression: loss=0.3022959601964204\n",
      "Lambda 0.00010826367338740541, Train accuracy 0.7882533333333334, Validation Accuracy 0.78832\n",
      "Ridge Regression: loss=0.3029820568718427\n",
      "Lambda 0.0001610262027560939, Train accuracy 0.7874933333333334, Validation Accuracy 0.78816\n",
      "Ridge Regression: loss=0.30368740657239013\n",
      "Lambda 0.0002395026619987486, Train accuracy 0.7866844444444444, Validation Accuracy 0.78712\n",
      "Ridge Regression: loss=0.3044457640253259\n",
      "Lambda 0.0003562247890262444, Train accuracy 0.7857511111111111, Validation Accuracy 0.78664\n",
      "Ridge Regression: loss=0.30527009594499416\n",
      "Lambda 0.0005298316906283713, Train accuracy 0.7846177777777777, Validation Accuracy 0.78532\n",
      "Ridge Regression: loss=0.3061414671489425\n",
      "Lambda 0.0007880462815669912, Train accuracy 0.7839155555555556, Validation Accuracy 0.78488\n",
      "Ridge Regression: loss=0.30701748854129496\n",
      "Lambda 0.0011721022975334804, Train accuracy 0.7828977777777778, Validation Accuracy 0.78344\n",
      "Ridge Regression: loss=0.3078537169052092\n",
      "Lambda 0.001743328822199989, Train accuracy 0.7819955555555556, Validation Accuracy 0.78284\n",
      "Ridge Regression: loss=0.30862294375600396\n",
      "Lambda 0.002592943797404667, Train accuracy 0.7811511111111111, Validation Accuracy 0.78208\n",
      "Ridge Regression: loss=0.3093227305053389\n",
      "Lambda 0.0038566204211634724, Train accuracy 0.7803777777777777, Validation Accuracy 0.78168\n",
      "Ridge Regression: loss=0.30997248440880415\n",
      "Lambda 0.005736152510448681, Train accuracy 0.7798355555555555, Validation Accuracy 0.78164\n",
      "Ridge Regression: loss=0.31060621092382895\n",
      "Lambda 0.008531678524172814, Train accuracy 0.7793511111111111, Validation Accuracy 0.78176\n",
      "Ridge Regression: loss=0.31126667713745654\n",
      "Lambda 0.012689610031679234, Train accuracy 0.7788888888888889, Validation Accuracy 0.7808\n",
      "Ridge Regression: loss=0.3120051120750934\n",
      "Lambda 0.018873918221350976, Train accuracy 0.77824, Validation Accuracy 0.7802\n",
      "Ridge Regression: loss=0.3128859796076067\n",
      "Lambda 0.028072162039411784, Train accuracy 0.7777422222222222, Validation Accuracy 0.78012\n",
      "Ridge Regression: loss=0.3139889394922397\n",
      "Lambda 0.04175318936560404, Train accuracy 0.7771555555555556, Validation Accuracy 0.78\n",
      "Ridge Regression: loss=0.3153972858452061\n",
      "Lambda 0.06210169418915616, Train accuracy 0.7759955555555555, Validation Accuracy 0.77788\n",
      "Ridge Regression: loss=0.3171702428153908\n",
      "Lambda 0.09236708571873865, Train accuracy 0.7745244444444445, Validation Accuracy 0.776\n",
      "Ridge Regression: loss=0.31931265365941336\n",
      "Lambda 0.1373823795883264, Train accuracy 0.7726355555555555, Validation Accuracy 0.77468\n",
      "Ridge Regression: loss=0.32176672002899176\n",
      "Lambda 0.20433597178569438, Train accuracy 0.7701333333333333, Validation Accuracy 0.7728\n",
      "Ridge Regression: loss=0.3244419027948171\n",
      "Lambda 0.3039195382313201, Train accuracy 0.7671733333333334, Validation Accuracy 0.76932\n",
      "Ridge Regression: loss=0.32727010744515217\n",
      "Lambda 0.452035365636025, Train accuracy 0.7630933333333333, Validation Accuracy 0.76636\n",
      "Ridge Regression: loss=0.3302504881695835\n",
      "Lambda 0.6723357536499335, Train accuracy 0.7588666666666667, Validation Accuracy 0.76348\n",
      "Ridge Regression: loss=0.33344923154287953\n",
      "Lambda 1.0, Train accuracy 0.7545333333333333, Validation Accuracy 0.75912\n"
     ]
    }
   ],
   "source": [
    "# polynomial fit\n",
    "\n",
    "ratio = 0.9\n",
    "degree = 7\n",
    "seed = 6\n",
    "k_fold = 4\n",
    "\n",
    "x_train, y_train, x_val, y_val = split_data(tX, y, ratio, seed)\n",
    "x_train_poly = build_poly(x_train, degree)\n",
    "x_val_poly = build_poly(x_val, degree)\n",
    "initial_w = np.zeros(tX.shape[1]*degree)\n",
    "\n",
    "lambdas = np.logspace(-5, 0, 30)\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    weights, loss = ridge_regression(y_train, x_train_poly, lambda_)\n",
    "\n",
    "    y_train_pred = predict_labels(weights, x_train_poly)\n",
    "    train_acc = cal_acc(y_train, y_train_pred)\n",
    "    y_val_pred = predict_labels(weights, x_val_poly)\n",
    "    val_acc = cal_acc(y_val, y_val_pred)\n",
    "\n",
    "    print(\"Lambda {labd}, Train accuracy {ta}, Validation Accuracy {va}\".format(labd=lambda_, ta=train_acc, va=val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: loss=0.29976130226731296\n",
      "0.791032\n"
     ]
    }
   ],
   "source": [
    "# best para\n",
    "\n",
    "ratio = 0.9\n",
    "degree = 8\n",
    "lambda_ = 5.2983169062837125e-05\n",
    "seed = 6\n",
    "\n",
    "x_poly = build_poly(tX, degree)\n",
    "weights, loss = ridge_regression(y, x_poly, lambda_)\n",
    "\n",
    "pred = predict_labels(weights, x_poly)\n",
    "acc = cal_acc(y, pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "# pre-process\n",
    "tX_test = tX_test / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "# y_pred = predict_labels(weights, tX_test)\n",
    "# for polynomial fit\n",
    "x_test_poly = build_poly(tX_test, degree)\n",
    "y_pred = predict_labels(weights, x_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "4f70402bd64a83f9e6e93d3db4ad4ffb184214f121a586f2f8f605e1d305850e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ada': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
